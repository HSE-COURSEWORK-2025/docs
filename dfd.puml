@startuml
!define AWSPUML https://raw.githubusercontent.com/awslabs/aws-icons-for-plantuml/v14.0/LATEST/AWSPUML
skinparam dpi 150
title DFD: Сервис мониторинга здоровья с ML‑анализом

actor "Носимое устройство" as Wearable

rectangle "Приложение\nGoogle Fit" as GFitApp
rectangle "Google Fitness API" as GFitAPI

rectangle "Мобильное приложение\n(Android)" as Mobile
rectangle "Веб‑интерфейс\n(React)" as Web

rectangle "Сервис авторизации\n(FastAPI)" as Auth
rectangle "Сервис приёма данных\n(FastAPI)" as Ingest
queue "Очередь\nApache Kafka" as Kafka
rectangle "Рабочий процессор\nDramatiq" as Worker
database "БД PostgreSQL" as DB

rectangle "Процесс сбора из Google Fitness\n(Airflow)" as AirflowG
rectangle "Процесс обнаружения выбросов\n(Airflow)" as Airflow1
rectangle "Процесс ML‑анализа\n(Airflow)" as Airflow2
rectangle "Процесс предобработки исходных данных" as Airflow3

rectangle "Сервис прогнозирования\n(FastAPI)" as PredService

' Поток данных от носимого устройства напрямую в мобильное приложение
Wearable --> Mobile             : Сырые данные (пульс, шаги и т.д.)

' Поток данных из носимого устройства через Google Fit
Wearable --> GFitApp           : Метрики (пульс, шаги и т.д.)
GFitApp --> GFitAPI            : Синхронизация данных

' Сбор данных из Google Fitness API через Airflow
GFitAPI --> AirflowG           : GET новые метрики
AirflowG --> Ingest            : HTTP POST raw_data

' Прямая отправка из мобильного приложения
Mobile --> Ingest              : HTTP POST raw_data

' Аутентификация пользователя
Web --> Auth                   : OAuth‑запрос (Google)
Auth --> Web                   : JWT‑токен

' Ингест и очередь
Ingest --> Kafka               : Публикация сообщений
Kafka --> Worker               : Подписка и чтение сообщений
Worker --> DB                  : INSERT в raw_data

' Обнаружение выбросов
DB --> Airflow1                : SELECT raw_data
Airflow1 --> DB                : INSERT в data_outliers

' ML‑анализ
DB --> Airflow2                : SELECT raw_data
Airflow2 --> DB                : INSERT в predictions


' preparation
DB --> Airflow3                : SELECT raw_data
Airflow3 --> DB                : INSERT в processed_data

' Фронтенд получает данные от сервиса приёма
Web --> Ingest                 : GET /raw_data
Ingest --> Web                 : JSON сырые данные

Web --> Ingest                 : GET /outliers
Ingest --> Web                 : JSON выбросы

Web --> Ingest                 : GET /predictions
Ingest --> Web                 : JSON предсказания

@enduml
